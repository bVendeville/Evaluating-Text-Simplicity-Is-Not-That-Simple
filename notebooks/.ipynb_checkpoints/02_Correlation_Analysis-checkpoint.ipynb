{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Correlation Analysis\n",
    "\n",
    "Compute Pearson, Spearman, and Kendall correlations between metrics and human simplicity scores.\n",
    "All correlations are reported as **absolute values** since we care about strength of relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data_loader import load_all_datasets, get_metric_names\n",
    "from src.statistics import compute_all_correlations, compute_metric_correlations\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "results_dir = project_root / 'results'\n",
    "figures_dir = results_dir / 'figures'\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_all_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute All Correlations (Pearson, Spearman, Kendall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all three correlation types for each dataset\n",
    "correlation_results = {}\n",
    "\n",
    "for dataset_name, data in datasets.items():\n",
    "    print(f'\\n{dataset_name}:')\n",
    "    \n",
    "    human = data['human_scores']\n",
    "    metrics = {k: v for k, v in data['metric_scores'].items() if k != 'human'}\n",
    "    \n",
    "    # Compute Pearson, Spearman, and Kendall correlations\n",
    "    corr_df = compute_all_correlations(metrics, human)\n",
    "    correlation_results[dataset_name] = corr_df\n",
    "    \n",
    "    print(f'  Samples: {data[\"n_samples\"]}')\n",
    "    print(f'  Metrics: {len(corr_df)}')\n",
    "    if len(corr_df) > 0:\n",
    "        best = corr_df.iloc[0]\n",
    "        print(f'  Best (avg |r|): {best[\"metric\"]} ({best[\"avg_abs\"]:.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlation Tables by Dataset\n",
    "\n",
    "Showing absolute correlations (|r|) for Pearson, Spearman, and Kendall's tau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display correlation tables for key datasets\n",
    "for dataset_name in ['ARTS3k', 'SDA', 'ST-sent', 'D-Wiki']:\n",
    "    if dataset_name in correlation_results:\n",
    "        print(f'\\n{dataset_name} - Absolute Correlations:')\n",
    "        print('=' * 80)\n",
    "        \n",
    "        df = correlation_results[dataset_name].copy()\n",
    "        \n",
    "        # Display absolute correlations\n",
    "        display_df = df[['metric', 'P_abs', 'S_abs', 'K_abs', 'avg_abs', 'n']].copy()\n",
    "        display_df.columns = ['Metric', '|Pearson|', '|Spearman|', '|Kendall|', 'Average', 'N']\n",
    "        display_df = display_df.round(3)\n",
    "        \n",
    "        display(display_df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-Dataset Comparison Matrix\n",
    "\n",
    "Average absolute correlation across Pearson, Spearman, and Kendall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Build comparison matrix (metrics x datasets) using average absolute correlation\nall_metrics = set()\nfor df in correlation_results.values():\n    all_metrics.update(df['metric'].tolist())\n\ncomparison_data = {}\nfor dataset_name, df in correlation_results.items():\n    metric_to_corr = dict(zip(df['metric'], df['avg_abs']))\n    comparison_data[dataset_name] = metric_to_corr\n\ncomparison_df = pd.DataFrame(comparison_data)\n\n# Reorder columns\ncol_order = ['ARTS94', 'ARTS300', 'ARTS3k', 'LR-ARTS94', 'LR-ARTS300', 'LR-ARTS3k', 'SDA', 'ST-sent', 'ST-para', 'D-Wiki']\ncol_order = [c for c in col_order if c in comparison_df.columns]\ncomparison_df = comparison_df[col_order]\n\n# Sort by average\ncomparison_df['Average'] = comparison_df.mean(axis=1)\ncomparison_df = comparison_df.sort_values('Average', ascending=False)\n\nprint('Average Absolute Correlation |r| (Metric vs Human):')\ndisplay(comparison_df.round(3))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of absolute correlations\n",
    "plot_df = comparison_df.drop(columns=['Average'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "sns.heatmap(\n",
    "    plot_df,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='YlGn',\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    ax=ax,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={'label': 'Absolute Correlation |r|'},\n",
    ")\n",
    "\n",
    "ax.set_title('Average Absolute Correlation with Human Scores\\n(Pearson, Spearman, Kendall)', fontsize=14)\n",
    "ax.set_xlabel('Dataset')\n",
    "ax.set_ylabel('Metric')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.savefig(figures_dir / 'correlation_heatmap.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: correlation_heatmap.png/pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation Method Comparison\n",
    "\n",
    "Compare Pearson vs Spearman vs Kendall for each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ARTS3k, compare the three methods\n",
    "dataset_name = 'ARTS3k'\n",
    "df = correlation_results[dataset_name]\n",
    "\n",
    "print(f'{dataset_name} - Correlation Method Comparison:')\n",
    "print('=' * 70)\n",
    "\n",
    "method_df = df[['metric', 'P_abs', 'S_abs', 'K_abs']].copy()\n",
    "method_df.columns = ['Metric', 'Pearson', 'Spearman', 'Kendall']\n",
    "method_df['Max'] = method_df[['Pearson', 'Spearman', 'Kendall']].max(axis=1)\n",
    "method_df['Min'] = method_df[['Pearson', 'Spearman', 'Kendall']].min(axis=1)\n",
    "method_df['Range'] = method_df['Max'] - method_df['Min']\n",
    "\n",
    "display(method_df.round(3))\n",
    "\n",
    "print(f'\\nAverage range across methods: {method_df[\"Range\"].mean():.3f}')\n",
    "print('(Lower range = more consistent across correlation types)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ranking by Average Absolute Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final ranking\n",
    "comparison_df['Count'] = comparison_df.drop(columns=['Average']).notna().sum(axis=1)\n",
    "ranking = comparison_df[['Average', 'Count']].sort_values('Average', ascending=False)\n",
    "\n",
    "print('Average Absolute Correlation Across All Datasets:')\n",
    "print('=' * 50)\n",
    "display(ranking.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CORRELATION ANALYSIS SUMMARY')\n",
    "print('=' * 60)\n",
    "print(f'Datasets analyzed: {len(correlation_results)}')\n",
    "print(f'Unique metrics: {len(all_metrics)}')\n",
    "print('\\nCorrelation methods: Pearson, Spearman, Kendall')\n",
    "print('All values reported as absolute correlations |r|')\n",
    "\n",
    "print('\\nBest Metric per Dataset (by avg |r|):')\n",
    "for dataset_name, df in correlation_results.items():\n",
    "    if len(df) > 0:\n",
    "        best = df.iloc[0]\n",
    "        print(f'  {dataset_name}: {best[\"metric\"]} (|r|={best[\"avg_abs\"]:.3f})')\n",
    "\n",
    "print('\\nTop 5 by Average Absolute Correlation:')\n",
    "for i, (metric, row) in enumerate(ranking.head(5).iterrows(), 1):\n",
    "    print(f'  {i}. {metric}: |r|={row[\"Average\"]:.3f} (in {int(row[\"Count\"])} datasets)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}